{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version: 1.13.1+cu117\n",
            "Cuda available: True\n",
            "Torch geometric version: 2.2.0\n",
            "Torch version: 1.13.1+cu117\n",
            "Cuda available: True\n",
            "Torch geometric version: 2.2.0\n"
          ]
        }
      ],
      "source": [
        "# SELF REMINDER. Copy the 'ocpa' directory to the forked one from github, so that I can push updates to github.\n",
        "# Python native\n",
        "import pickle\n",
        "from statistics import median, mean\n",
        "import pandas as pd\n",
        "# Data handling\n",
        "# Object centric process mining\n",
        "# import ocpa.algo.evaluation.precision_and_fitness.utils as evaluation_utils # COMMENTED OUT BY TIM\n",
        "# import ocpa.algo.evaluation.precision_and_fitness.evaluator as precision_fitness_evaluator # COMMENTED OUT BY TIM\n",
        "import ocpa.objects.log.importer.csv.factory as csv_import_factory\n",
        "import ocpa.algo.predictive_monitoring.factory as feature_factory\n",
        "from ocpa.objects.log.ocel import OCEL\n",
        "\n",
        "# # Simple machine learning models, procedure tools, and evaluation metrics\n",
        "# from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# # Custom GNN tools\n",
        "# from gnn_utils import (\n",
        "#     generate_graph_dataset,\n",
        "#     # get_ordered_event_list,\n",
        "#     # visualize_graph,\n",
        "#     # show_remaining_times,\n",
        "#     # visualize_instance,\n",
        "#     # GraphDataLoader,\n",
        "#     # GCN,\n",
        "#     # evaluate_gnn,\n",
        "# )\n",
        "\n",
        "# PyG\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from replicating.ocpa_PyG_integration.EventGraphDataset import EventGraphDataset\n",
        "from replicating.ocpa_PyG_integration.EventSubGraphDataset import EventSubGraphDataset\n",
        "from replicating.model import GCN, GAT\n",
        "\n",
        "# Global variables\n",
        "from replicating.experiment_config import STORAGE_PATH, FEATURE_STORAGE_FILE, RANDOM_SEED, TARGET_LABEL\n",
        "\n",
        "\n",
        "filename = \"data/adams/example_logs/mdl/BPI2017-Final.csv\"\n",
        "object_types = [\"application\", \"offer\"]\n",
        "parameters = {\n",
        "    \"obj_names\": object_types,\n",
        "    \"val_names\": [],\n",
        "    \"act_name\": \"event_activity\",\n",
        "    \"time_name\": \"event_timestamp\",\n",
        "    \"sep\": \",\",\n",
        "}\n",
        "file_path_object_attribute_table = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No EventSubGraphDataset found with this configuration in 'data/ocpa-processed/processed'. Proceeding to processing...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "6302it [00:00, 783882.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GraphLevelData(x=[40, 24], edge_index=[2, 48], y=-0.9933435320854187)\n",
            "GraphLevelData(x=[40, 24], edge_index=[2, 48], y=-0.9933435916900635)\n",
            "GraphLevelData(x=[40, 24], edge_index=[2, 47], y=-0.9236124753952026)\n",
            "GraphLevelData(x=[40, 24], edge_index=[2, 47], y=-0.9238334894180298)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "ds_val = EventSubGraphDataset(\n",
        "    root=STORAGE_PATH,\n",
        "    filename=FEATURE_STORAGE_FILE,\n",
        "    label_key=TARGET_LABEL,\n",
        "    size_subgraph_samples=40,\n",
        "    validation=True,\n",
        "    verbosity=51\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['y', 'edge_index', 'x']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g = ds_val.get(3)\n",
        "g.keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch_geometric.loader.dataloader.DataLoader at 0x7fa4727d0640>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_loader = DataLoader(ds_val,2,shuffle=True,pin_memory=True)\n",
        "val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Could not infer dtype of NoneType",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(val_loader))\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(batch)\n\u001b[1;32m      3\u001b[0m \u001b[39m# print(batch.x)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# print(batch.y.shape)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# print(batch.y)\u001b[39;00m\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch_geometric/loader/dataloader.py:19\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m elem \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m Batch\u001b[39m.\u001b[39;49mfrom_data_list(batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfollow_batch,\n\u001b[1;32m     20\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexclude_keys)\n\u001b[1;32m     21\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m default_collate(batch)\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch_geometric/data/batch.py:76\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_data_list\u001b[39m(\u001b[39mcls\u001b[39m, data_list: List[BaseData],\n\u001b[1;32m     66\u001b[0m                    follow_batch: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m                    exclude_keys: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     batch, slice_dict, inc_dict \u001b[39m=\u001b[39m collate(\n\u001b[1;32m     77\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m     78\u001b[0m         data_list\u001b[39m=\u001b[39;49mdata_list,\n\u001b[1;32m     79\u001b[0m         increment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     80\u001b[0m         add_batch\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data_list[\u001b[39m0\u001b[39;49m], Batch),\n\u001b[1;32m     81\u001b[0m         follow_batch\u001b[39m=\u001b[39;49mfollow_batch,\n\u001b[1;32m     82\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49mexclude_keys,\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     85\u001b[0m     batch\u001b[39m.\u001b[39m_num_graphs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[1;32m     86\u001b[0m     batch\u001b[39m.\u001b[39m_slice_dict \u001b[39m=\u001b[39m slice_dict\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch_geometric/data/collate.py:84\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m value, slices, incs \u001b[39m=\u001b[39m _collate(attr, values, data_list, stores,\n\u001b[1;32m     85\u001b[0m                                increment)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mis_cuda:\n\u001b[1;32m     88\u001b[0m     device \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mdevice\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch_geometric/data/collate.py:133\u001b[0m, in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    131\u001b[0m slices \u001b[39m=\u001b[39m cumsum([value\u001b[39m.\u001b[39msize(cat_dim \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m values])\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m increment:\n\u001b[0;32m--> 133\u001b[0m     incs \u001b[39m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m incs\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mint\u001b[39m(incs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m         values \u001b[39m=\u001b[39m [\n\u001b[1;32m    136\u001b[0m             value \u001b[39m+\u001b[39m inc\u001b[39m.\u001b[39mto(value\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    137\u001b[0m             \u001b[39mfor\u001b[39;00m value, inc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(values, incs)\n\u001b[1;32m    138\u001b[0m         ]\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch_geometric/data/collate.py:269\u001b[0m, in \u001b[0;36mget_incs\u001b[0;34m(key, values, data_list, stores)\u001b[0m\n\u001b[1;32m    267\u001b[0m     repeats \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(repeats, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    268\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     repeats \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(repeats)\n\u001b[1;32m    270\u001b[0m \u001b[39mreturn\u001b[39;00m cumsum(repeats[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType"
          ]
        }
      ],
      "source": [
        "batch = next(iter(val_loader))\n",
        "print(batch)\n",
        "# print(batch.x)\n",
        "# print(batch.y.shape)\n",
        "# print(batch.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 DataBatch(x=[80, 24], edge_index=[2, 94], y=[2], batch=[80], ptr=[3])\n",
            "1 DataBatch(x=[80, 24], edge_index=[2, 96], y=[2], batch=[80], ptr=[3])\n"
          ]
        }
      ],
      "source": [
        "for i, batch in enumerate(val_loader):\n",
        "    print(i, batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m loss_fn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mL1Loss()\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(ds_val, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      6\u001b[0m running_vloss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch_geometric/loader/dataloader.py:78\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_batch \u001b[39m=\u001b[39m follow_batch\n\u001b[1;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexclude_keys \u001b[39m=\u001b[39m exclude_keys\n\u001b[0;32m---> 78\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     79\u001b[0m     dataset,\n\u001b[1;32m     80\u001b[0m     batch_size,\n\u001b[1;32m     81\u001b[0m     shuffle,\n\u001b[1;32m     82\u001b[0m     collate_fn\u001b[39m=\u001b[39;49mCollater(follow_batch, exclude_keys),\n\u001b[1;32m     83\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     84\u001b[0m )\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 344\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[0;32m~/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch/utils/data/sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GCN(24, {\"num_hidden_features\": 24})\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "model = model.to(device)\n",
        "val_loader = DataLoader(ds_val, batch_size=64, shuffle=True)\n",
        "running_vloss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tim/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/home/tim/Development/OCELFeatureExtractionExperiments/.env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([156])) that is different to the input size (torch.Size([156, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i, vdata in enumerate(val_loader):\n",
        "            vdata.to(device)\n",
        "            vinputs, vadjacency_matrix, vlabels = (\n",
        "                vdata.x.float(),\n",
        "                vdata.edge_index,\n",
        "                vdata.y.float(),\n",
        "            )\n",
        "            voutputs = model(vinputs, vadjacency_matrix)\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "15754it [01:22, 190.43it/s]\n",
            "Done!\n",
            "Processing...\n",
            "6302it [00:31, 200.10it/s]\n",
            "Done!\n",
            "Processing...\n",
            "9453it [00:49, 191.69it/s]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "ds_train = EventSubGraphDataset(\n",
        "    root=STORAGE_PATH,\n",
        "    filename=FEATURE_STORAGE_FILE,\n",
        "    label_key=TARGET_LABEL,\n",
        "    size_subgraph_samples=4,\n",
        "    train=True,\n",
        "    verbosity=51\n",
        ")\n",
        "ds_val = EventSubGraphDataset(\n",
        "    root=STORAGE_PATH,\n",
        "    filename=FEATURE_STORAGE_FILE,\n",
        "    label_key=TARGET_LABEL,\n",
        "    size_subgraph_samples=4,\n",
        "    validation=True,\n",
        "    verbosity=51\n",
        ")\n",
        "ds_test = EventSubGraphDataset(\n",
        "    root=STORAGE_PATH,\n",
        "    filename=FEATURE_STORAGE_FILE,\n",
        "    label_key=TARGET_LABEL,\n",
        "    size_subgraph_samples=4,\n",
        "    test=True,\n",
        "    verbosity=51\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "150012"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_train.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing OCEL\n",
        "ocel = csv_import_factory.apply(\n",
        "    filename, csv_import_factory.TO_OCEL, parameters, file_path_object_attribute_table\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f\"debug/self._mapping-pass.pkl\", \"rb\") as file:\n",
        "    mapping_pass = pickle.load(file)\n",
        "with open(\"debug/attribute-pass.pkl\", \"rb\") as file:\n",
        "    attribute_pass = pickle.load(file)\n",
        "with open(\"debug/e_id-pass.pkl\", \"rb\") as file:\n",
        "    e_id_pass = pickle.load(file)\n",
        "with open(\"debug/self._mapping[attribute][e_id]-pass.pkl\", \"rb\") as file:\n",
        "    value_pass = pickle.load(file)\n",
        "\n",
        "with open(f\"debug/self._mapping-fail.pkl\", \"rb\") as file:\n",
        "    mapping_fail = pickle.load(file)\n",
        "with open(\"debug/attribute-fail.pkl\", \"rb\") as file:\n",
        "    attribute_fail = pickle.load(file)\n",
        "with open(\"debug/e_id-fail.pkl\", \"rb\") as file:\n",
        "    e_id_fail = pickle.load(file)\n",
        "\n",
        "with open(\"debug/ocel.log\", \"rb\") as file:\n",
        "    ocel_log = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "map = pd.DataFrame(ocel.log._mapping)\n",
        "map.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ocel.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping_pass = pd.DataFrame(mapping_pass)\n",
        "print(attribute_pass)\n",
        "print(e_id_pass)\n",
        "print(value_pass)\n",
        "mapping_pass.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping_fail = pd.DataFrame(mapping_fail)\n",
        "print(attribute_fail)\n",
        "print(e_id_fail)\n",
        "mapping_fail.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "            self._mapping[attribute][e_id]\n",
        "            with open(\"self._mapping-pass.pkl\", \"wb\") as file:\n",
        "                pickle.dump(self._mapping, file)\n",
        "            with open(\"attribute-pass.pkl\", \"wb\") as file:\n",
        "                pickle.dump(attribute, file)\n",
        "            with open(\"e_id-pass.pkl\", \"wb\") as file:\n",
        "                pickle.dump(e_id, file)\n",
        "            with open(\"self._mapping[attribute][e_id]-pass.pkl\", \"wb\") as file:\n",
        "                pickle.dump(self._mapping[attribute][e_id], file)\n",
        "        except:\n",
        "            with open(\"self._mapping-fail.pkl\", \"wb\") as file:\n",
        "                pickle.dump(self._mapping, file)\n",
        "            with open(\"attribute-fail.pkl\", \"wb\") as file:\n",
        "                pickle.dump(attribute, file)\n",
        "            with open(\"e_id-fail.pkl\", \"wb\") as file:\n",
        "                pickle.dump(e_id, file)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
