{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tim\\Development\\OCELFeatureExtractionExperiments\\.env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.13.1+cpu\n",
      "Cuda available: False\n",
      "Torch geometric version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# SELF REMINDER. Copy the 'ocpa' directory to the forked one from github, so that I can push updates to github.\n",
    "\n",
    "# Python native\n",
    "import pickle\n",
    "from statistics import median as median\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.chdir(\"c:\\\\Users\\\\Tim\\\\Development\\\\OCELFeatureExtractionExperiments\")\n",
    "from copy import deepcopy\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Object centric process mining\n",
    "from ocpa.algo.predictive_monitoring.obj import Feature_Storage as FeatureStorage\n",
    "\n",
    "# PyG\n",
    "import torch\n",
    "from ocpa_PyG_integration.PyG_dataset import EventGraphDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model) ->int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "22056it [01:07, 326.93it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ds_train = EventGraphDataset(\n",
    "    root=\"data/ocpa-processed/\",\n",
    "    filename=\"BPI2017-feature_storage_split.pkl\",\n",
    "    label_key=(\"event_remaining_time\", ()),\n",
    "    train=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "9453it [00:31, 302.11it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ds_test = EventGraphDataset(\n",
    "    root=\"data/ocpa-processed/\",\n",
    "    filename=\"BPI2017-feature_storage_split.pkl\",\n",
    "    label_key=(\"event_remaining_time\", ()),\n",
    "    test=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22056/22056 [00:54<00:00, 403.23it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EventGraphDataset (#graphs=22056):\n",
       "+------------+----------+----------+\n",
       "|            |   #nodes |   #edges |\n",
       "|------------+----------+----------|\n",
       "| mean       |     12.5 |     13.7 |\n",
       "| std        |      3.6 |      4.5 |\n",
       "| min        |      6   |      5   |\n",
       "| quantile25 |     10   |     11   |\n",
       "| median     |     12   |     13   |\n",
       "| quantile75 |     14   |     16   |\n",
       "| max        |     41   |     54   |\n",
       "+------------+----------+----------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm updated!\n",
      "GCN(\n",
      "  (conv1): GCNConv(23, 12)\n",
      "  (conv2): GCNConv(12, 12)\n",
      "  (out): Linear(in_features=12, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters: 457\n"
     ]
    }
   ],
   "source": [
    "from model import GCN\n",
    "import torch \n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = GCN(ds_train.num_node_features, 12)\n",
    "print(model)\n",
    "print(f'Number of parameters: {count_parameters(model)}')\n",
    "\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "# data = ds_train.to(device)\n",
    "\n",
    "# Initialize Optimizer\n",
    "learning_rate = 0.01\n",
    "decay = 5e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=decay)\n",
    "NUM_GRAPHS_PER_BATCH = 512\n",
    "# Define loss function (CrossEntropyLoss for Classification Problems with \n",
    "# probability distributions)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_loader = DataLoader(ds_train,batch_size=NUM_GRAPHS_PER_BATCH,shuffle=True)\n",
    "test_loader = DataLoader(ds_test,batch_size=NUM_GRAPHS_PER_BATCH,shuffle=True)\n",
    "\n",
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    print(f\"\\n MAE: \\n {mean_absolute_error(y_pred, y_true)}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_true, y_pred)}\")\n",
    "    print(f\"R^2: {r2_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(epoch):\n",
    "      all_preds = []\n",
    "      all_labels = []\n",
    "\n",
    "      model.train()\n",
    "      optimizer.zero_grad() \n",
    "      # Use all data as input, because all nodes have node features\n",
    "      out = model(data.x, data.edge_index)  \n",
    "      # Only use nodes with labels available for loss calculation --> mask\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  \n",
    "      loss.backward() \n",
    "      optimizer.step()\n",
    "      return loss\n",
    "\n",
    "def train_one_epoch(epoch, model, train_loader, optimizer, loss_fn):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for _, batch in enumerate(tqdm(train_loader)):\n",
    "        # Use GPU\n",
    "        batch.to(device)  \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(batch.x.float(), \n",
    "                                batch.edge_index, \n",
    "                                batch.batch) \n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        print(f'{running_loss} \\r', end=\" \")\n",
    "        print(f'{step} \\r', end=\" \")\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    \n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return running_loss/step\n",
    "\n",
    "def test(epoch, model, test_loader, loss_fn):\n",
    "    all_preds = []\n",
    "    all_preds_raw = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)  \n",
    "        pred = model(batch.x.float(), \n",
    "                        batch.edge_index, \n",
    "                        batch.batch) \n",
    "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
    "\n",
    "         # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_preds_raw.append(torch.sigmoid(pred).cpu().detach().numpy())\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    print(all_preds_raw[0][:10])\n",
    "    print(all_preds[:10])\n",
    "    print(all_labels[:10])\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    return running_loss/step\n",
    "\n",
    "def run_training(loss_fn):\n",
    "    \n",
    "    # Start training\n",
    "    best_loss = 1000\n",
    "    early_stopping_counter = 0\n",
    "    for epoch in range(300): \n",
    "        if early_stopping_counter <= 10: # = x * 5 \n",
    "            # Training\n",
    "            model.train()\n",
    "            loss = train_one_epoch(epoch, model, train_loader, optimizer, loss_fn)\n",
    "            print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
    "\n",
    "            # Testing\n",
    "            model.eval()\n",
    "            if epoch % 5 == 0:\n",
    "                loss = test(epoch, model, test_loader, loss_fn)\n",
    "                print(f\"Epoch {epoch} | Test Loss {loss}\")\n",
    "                \n",
    "                # Update best loss\n",
    "                if float(loss) < best_loss:\n",
    "                    best_loss = loss\n",
    "                    # # Save the currently best model \n",
    "                    # mlflow.pytorch.log_model(model, \"model\", signature=SIGNATURE)\n",
    "                    early_stopping_counter = 0\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "        else:\n",
    "            print(\"Early stopping due to no improvement.\")\n",
    "            return [best_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m run_training(criterion)\n",
      "Cell \u001b[1;32mIn[6], line 85\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(loss_fn)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m early_stopping_counter \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m10\u001b[39m: \u001b[39m# = x * 5 \u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[39m# Training\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 85\u001b[0m     loss \u001b[39m=\u001b[39m train_one_epoch(epoch, model, train_loader, optimizer, loss_fn)\n\u001b[0;32m     86\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | Train Loss \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     \u001b[39m# Testing\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch, model, train_loader, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \n\u001b[0;32m     26\u001b[0m \u001b[39m# Passing the node features and the connection info\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m pred \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49mfloat(), \n\u001b[0;32m     28\u001b[0m                         batch\u001b[39m.\u001b[39;49medge_index, \n\u001b[0;32m     29\u001b[0m                         batch\u001b[39m.\u001b[39;49mbatch) \n\u001b[0;32m     30\u001b[0m \u001b[39m# Calculating the loss and gradients\u001b[39;00m\n\u001b[0;32m     31\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(torch\u001b[39m.\u001b[39msqueeze(pred), batch\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mfloat())\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Development\\OCELFeatureExtractionExperiments\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "results = run_training(criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fbe1a019293c11979212df1017f5c3a8203512503371a115c3974d4c744b0fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
